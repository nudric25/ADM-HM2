{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1876223,"sourceType":"datasetVersion","datasetId":1117005}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-29T09:29:48.107093Z","iopub.execute_input":"2024-10-29T09:29:48.107553Z","iopub.status.idle":"2024-10-29T09:29:48.528045Z","shell.execute_reply.started":"2024-10-29T09:29:48.107496Z","shell.execute_reply":"2024-10-29T09:29:48.526460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Percorso completo al file CSV\nfile_path = \"/kaggle/input/steam-reviews-2021/steam_reviews.csv\"\n\n# Carica solo le prime 2000 righe\ndf_sample = pd.read_csv(file_path, nrows=1000000)\n\n# Visualizza le prime righe per confermare\ndf_sample.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T09:29:50.567895Z","iopub.execute_input":"2024-10-29T09:29:50.569128Z","iopub.status.idle":"2024-10-29T09:29:59.697035Z","shell.execute_reply.started":"2024-10-29T09:29:50.569079Z","shell.execute_reply":"2024-10-29T09:29:59.695872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filtra le righe che contengono valori nulli\nrows_with_nulls = df_sample[df_sample.isnull().any(axis=1)]\n\n# Mostra le righe con valori nulli\nrows_with_nulls\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T09:30:02.376842Z","iopub.execute_input":"2024-10-29T09:30:02.377980Z","iopub.status.idle":"2024-10-29T09:30:02.560444Z","shell.execute_reply.started":"2024-10-29T09:30:02.377923Z","shell.execute_reply":"2024-10-29T09:30:02.559423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Elimina tutte le righe con valori nulli\ndf_sample.dropna(inplace=True)\n\n#dimensions of dataset after cleaner \ndf_sample.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-29T09:30:04.762981Z","iopub.execute_input":"2024-10-29T09:30:04.763453Z","iopub.status.idle":"2024-10-29T09:30:04.999215Z","shell.execute_reply.started":"2024-10-29T09:30:04.763408Z","shell.execute_reply":"2024-10-29T09:30:04.997778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plot the number of reviews submitted each month and describe any trends.\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Assicurati che il timestamp sia interpretato correttamente come datetime\ndf_sample['date'] = pd.to_datetime(df_sample['timestamp_created'], unit='s')\n\n# Estrai anno e mese e conta le recensioni per ogni mese\ndf_sample['year_month'] = df_sample['date'].dt.to_period('M')\nmonthly_reviews = df_sample.groupby('year_month').size()\n\n# Plot dei risultati\nplt.figure(figsize=(12, 6))\nmonthly_reviews.plot(kind='line', marker='o', color='b')\nplt.title('Number of Reviews Submitted Each Month')\nplt.xlabel('Month')\nplt.ylabel('Number of Reviews')\nplt.grid()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T09:30:06.943110Z","iopub.execute_input":"2024-10-29T09:30:06.943680Z","iopub.status.idle":"2024-10-29T09:30:07.587166Z","shell.execute_reply.started":"2024-10-29T09:30:06.943624Z","shell.execute_reply":"2024-10-29T09:30:07.585733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# description of plot\nThe graph shows the number of reviews submitted each month on Steam from 2011 to 2021. There is a clear upward trend in reviews over the years, with particularly high peaks occurring mainly in November. This may be linked to the Black Friday sales period and the holiday season, during which activity on Steam generally increases due to special offers.\n\nStarting from the end of 2019, there is a significant and continuous increase in the number of reviews, which remains high throughout 2020 and into early 2021. This increase could be attributed to various factors, including the impact of the COVID-19 pandemic, which led many people to spend more time on video games, thereby increasing the number of reviews on platforms like Steam.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Supponiamo che monthly_reviews sia una Series con l'indice di tipo DatetimeIndex\n\n# Creare una lista per memorizzare i risultati\nresults = []\n\n# Iterare su ogni anno per trovare il punto massimo\nfor year in monthly_reviews.index.year.unique():\n    # Selezionare i dati per l'anno corrente\n    yearly_data = monthly_reviews[monthly_reviews.index.year == year]\n    \n    # Trovare il mese con il numero massimo di recensioni\n    max_month = yearly_data.idxmax()\n    max_value = yearly_data[max_month]\n    \n    # Aggiungere i risultati alla lista\n    results.append({\n        'Year': year,\n        'Month': max_month.strftime(\"%B\"),  # Nome del mese\n        'Max Reviews': max_value\n    })\n\n# Creare un DataFrame dai risultati\nmax_reviews_per_year = pd.DataFrame(results)\n\n# Mostrare la tabella risultante\nprint(max_reviews_per_year)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T09:30:11.513150Z","iopub.execute_input":"2024-10-29T09:30:11.514248Z","iopub.status.idle":"2024-10-29T09:30:11.534953Z","shell.execute_reply.started":"2024-10-29T09:30:11.514182Z","shell.execute_reply":"2024-10-29T09:30:11.533593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Impostare il grafico\nplt.figure(figsize=(12, 6))\nplt.bar(max_reviews_per_year['Year'].astype(str), max_reviews_per_year['Max Reviews'], color='skyblue')\n\n# Aggiungere il titolo e le etichette\nplt.title('Massimo Numero di Recensioni per Anno', fontsize=16)\nplt.xlabel('Anno', fontsize=14)\nplt.ylabel('Numero Massimo di Recensioni', fontsize=14)\n\n# Annotare i mesi sui punti massimi\nfor index, row in max_reviews_per_year.iterrows():\n    plt.annotate(row['Month'], \n                 (str(row['Year']), row['Max Reviews']),  # Converti l'anno in stringa qui\n                 ha='center', \n                 va='bottom', \n                 fontsize=10)\n\n# Mostrare il grafico\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T09:30:14.382972Z","iopub.execute_input":"2024-10-29T09:30:14.383405Z","iopub.status.idle":"2024-10-29T09:30:14.813217Z","shell.execute_reply.started":"2024-10-29T09:30:14.383365Z","shell.execute_reply":"2024-10-29T09:30:14.811939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# description of plot\nThe trend observed in November, where peaks in reviews frequently occur, can be attributed to several key factors. This month is significant due to Black Friday and Cyber Monday sales, during which many games are heavily discounted, prompting increased purchases and reviews. Additionally, many developers launch new titles and DLCs in November to take advantage of the holiday shopping season, further driving review activity. As the holiday season approaches, people tend to spend more time playing games, leading to an uptick in reviews. Overall, from 2016 to 2021, November consistently shows high review activity, likely due to these combined factors.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\n# Assumiamo che df_sample sia il DataFrame contenente i dati delle recensioni\n# Convertiamo la colonna timestamp_created in un formato datetime con tqdm per monitorare il processo\ntqdm.pandas(desc=\"Conversione dei timestamp\")\ndf_sample['timestamp_created'] = pd.to_datetime(df_sample['timestamp_created'], unit='s')\n\n# Estraiamo solo ore e minuti dai timestamp e aggiorniamo con tqdm\ndf_sample['review_time'] = df_sample['timestamp_created'].progress_apply(lambda x: x.strftime('%H:%M'))\n\n# Calcoliamo la distribuzione delle recensioni per ogni orario (solo ore e minuti)\ntime_distribution = df_sample['review_time'].value_counts().sort_index()\n\n# Troviamo l'orario più comune\nmost_common_time = time_distribution.idxmax()\nmost_common_count = time_distribution.max()\n\nprint(f\"L'orario più comune per scrivere recensioni è {most_common_time} con {most_common_count} recensioni.\")\n\n# Creiamo un grafico della distribuzione delle recensioni nel tempo (solo ore e minuti)\nplt.figure(figsize=(12, 6))\ntime_distribution.plot(kind='bar', color='skyblue')\nplt.title('Distribuzione delle Recensioni nel Tempo (Ore e Minuti)', fontsize=16)\nplt.xlabel('Orario della Recensione (Ore:Minuti)', fontsize=14)\nplt.ylabel('Numero di Recensioni', fontsize=14)\nplt.xticks(rotation=45)\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T09:30:19.643758Z","iopub.execute_input":"2024-10-29T09:30:19.644168Z","iopub.status.idle":"2024-10-29T09:30:35.794909Z","shell.execute_reply.started":"2024-10-29T09:30:19.644131Z","shell.execute_reply":"2024-10-29T09:30:35.793668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The most common time for writing reviews\nThe most common time for writing reviews is 18:36, with a total of 768 reviews recorded at this exact minute. This concentration around a specific time may suggest that users often leave reviews in the evening, possibly after a full session of gameplay or as part of evening activities.\n\nThis timing insight is valuable, as it could indicate peak times when users are actively engaging with Steam's review system. Knowing that users tend to write reviews in the evening could guide decisions around customer support staffing or automated moderation during peak hours. Additionally, this peak timing could be used to target prompts or notifications encouraging users to leave reviews at similar times, enhancing overall user engagement.\n\n\n\n\n\n\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\n# Funzione per conteggiare e visualizzare le recensioni per ciascun intervallo di tempo\ndef plot_reviews_by_interval(df, intervals):\n    # Convertiamo il timestamp in datetime con tqdm per monitorare il processo\n    tqdm.pandas(desc=\"Conversione dei timestamp\")\n    df['timestamp_created'] = pd.to_datetime(df['timestamp_created'], unit='s')\n    df['hour'] = df['timestamp_created'].dt.hour\n    \n    # Creiamo un dizionario per memorizzare il conteggio delle recensioni per ciascun intervallo\n    interval_counts = {interval['name']: 0 for interval in intervals}\n\n    # Usiamo tqdm per tracciare il conteggio delle recensioni per ciascun intervallo\n    for index, row in tqdm(df.iterrows(), desc=\"Conteggio recensioni per intervallo\", total=df.shape[0]):\n        for interval in intervals:\n            start, end = interval['start'], interval['end']\n            if start <= row['hour'] < end:\n                interval_counts[interval['name']] += 1\n                break\n\n    # Converte il dizionario in DataFrame per la visualizzazione\n    interval_df = pd.DataFrame(list(interval_counts.items()), columns=['Interval', 'Review Count'])\n    \n    # Grafico del conteggio delle recensioni per intervallo di tempo\n    plt.figure(figsize=(10, 6))\n    plt.bar(interval_df['Interval'], interval_df['Review Count'], color='skyblue')\n    plt.title('Number of Reviews per Time Interval')\n    plt.xlabel('Time Interval')\n    plt.ylabel('Number of Reviews')\n    plt.xticks(rotation=45)\n    plt.grid(axis='y', linestyle='--', alpha=0.7)\n    plt.tight_layout()\n    plt.show()\n\n# Esempio di intervalli di tempo\nintervals = [\n    {'name': 'Morning (6AM-12PM)', 'start': 6, 'end': 12},\n    {'name': 'Afternoon (12PM-6PM)', 'start': 12, 'end': 18},\n    {'name': 'Evening (6PM-12AM)', 'start': 18, 'end': 24},\n    {'name': 'Night (12AM-6AM)', 'start': 0, 'end': 6}\n]\n\n# Chiama la funzione sul DataFrame\nplot_reviews_by_interval(df_sample, intervals)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T09:56:27.402567Z","iopub.execute_input":"2024-10-29T09:56:27.403033Z","iopub.status.idle":"2024-10-29T09:57:19.704783Z","shell.execute_reply.started":"2024-10-29T09:56:27.402990Z","shell.execute_reply":"2024-10-29T09:57:19.703676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\n# Funzione per conteggiare e visualizzare le recensioni per ciascun intervallo di tempo\ndef plot_reviews_by_interval(df, intervals):\n    # Convertiamo il timestamp in datetime con tqdm per monitorare il processo\n    tqdm.pandas(desc=\"Conversione dei timestamp\")\n    df['timestamp_created'] = pd.to_datetime(df['timestamp_created'], unit='s')\n    df['time'] = df['timestamp_created'].dt.time  # Estraiamo solo il tempo (HH:MM:SS)\n\n    # Creiamo un dizionario per memorizzare il conteggio delle recensioni per ciascun intervallo\n    interval_counts = {interval['name']: 0 for interval in intervals}\n\n    # Usiamo tqdm per tracciare il conteggio delle recensioni per ciascun intervallo\n    for index, row in tqdm(df.iterrows(), desc=\"Conteggio recensioni per intervallo\", total=df.shape[0]):\n        for interval in intervals:\n            if interval['start'] <= row['time'] <= interval['end']:\n                interval_counts[interval['name']] += 1\n                break\n\n    # Converte il dizionario in DataFrame per la visualizzazione\n    interval_df = pd.DataFrame(list(interval_counts.items()), columns=['Interval', 'Review Count'])\n    \n    # Grafico del conteggio delle recensioni per intervallo di tempo\n    plt.figure(figsize=(10, 6))\n    plt.bar(interval_df['Interval'], interval_df['Review Count'], color='skyblue')\n    plt.title('Number of Reviews per Time Interval')\n    plt.xlabel('Time Interval')\n    plt.ylabel('Number of Reviews')\n    plt.xticks(rotation=45)\n    plt.grid(axis='y', linestyle='--', alpha=0.7)\n    plt.tight_layout()\n    plt.show()\n\n# Esempio di intervalli di tempo con fasce specifiche\nintervals = [\n    {'name': '00:00-02:59', 'start': pd.to_datetime('00:00:00').time(), 'end': pd.to_datetime('02:59:59').time()},\n    {'name': '03:00-05:59', 'start': pd.to_datetime('03:00:00').time(), 'end': pd.to_datetime('05:59:59').time()},\n    {'name': '06:00-10:59', 'start': pd.to_datetime('06:00:00').time(), 'end': pd.to_datetime('10:59:59').time()},\n    {'name': '11:00-13:59', 'start': pd.to_datetime('11:00:00').time(), 'end': pd.to_datetime('13:59:59').time()},\n    {'name': '14:00-16:59', 'start': pd.to_datetime('14:00:00').time(), 'end': pd.to_datetime('16:59:59').time()},\n    {'name': '17:00-19:59', 'start': pd.to_datetime('17:00:00').time(), 'end': pd.to_datetime('19:59:59').time()},\n    {'name': '20:00-23:59', 'start': pd.to_datetime('20:00:00').time(), 'end': pd.to_datetime('23:59:59').time()}\n]\n\n# Chiama la funzione sul DataFrame\nplot_reviews_by_interval(df_sample, intervals)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T10:00:46.870227Z","iopub.execute_input":"2024-10-29T10:00:46.870745Z","iopub.status.idle":"2024-10-29T10:01:46.256802Z","shell.execute_reply.started":"2024-10-29T10:00:46.870690Z","shell.execute_reply":"2024-10-29T10:01:46.255384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# summary of results of section 3\nThe analysis of review submission patterns on Steam reveals several key insights. The first graph illustrates the number of reviews submitted each month from 2011 to 2021, showing a clear upward trend over the years. Notably, there are pronounced peaks in November, which align with Black Friday and Cyber Monday sales, as well as the holiday season, when discounted games and special offers tend to increase user engagement. The spikes in November may also be attributed to the launch of new titles and downloadable content (DLC) by developers aiming to capitalize on the heightened shopping activity during this period. Starting from late 2019, there is a substantial and sustained increase in reviews, continuing through 2020 and into early 2021. This increase is likely influenced by the COVID-19 pandemic, as more people spent time gaming and engaging with platforms like Steam.\n\nIn terms of specific timing, the second graph—showing the distribution of review submissions across different time intervals—indicates that the most common time for writing reviews is 18:36. This clustering around evening hours suggests that users often leave reviews after a full session of gameplay or as part of their evening activities. This insight into peak review times can be valuable for Steam’s customer support and moderation, as knowing when users are most active could help in optimizing staffing or automated moderation efforts. Additionally, this information can be used to target review prompts or notifications during evening hours, potentially increasing user engagement with the review system.\n\nOverall, these findings indicate that review activity is influenced by both seasonal sales events and daily gaming habits, with notable increases in November and during evening hours.","metadata":{}},{"cell_type":"markdown","source":"# Section 7","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Assumiamo che df_sample sia il DataFrame contenente i dati delle recensioni\n# Contiamo il numero totale di recensioni\ntotal_reviews = len(df_sample)\n\n# Contiamo quante recensioni non hanno ricevuto alcun voto utile\nreviews_with_no_votes = df_sample[df_sample['votes_helpful'] == 0].shape[0]\n\n# Calcoliamo la probabilità di ricevere almeno un voto utile\nP_X_0 = reviews_with_no_votes / total_reviews\nP_X_ge_1 = 1 - P_X_0\n\nprint(f\"La probabilità di ricevere almeno un voto utile è: {P_X_ge_1:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T10:28:28.768119Z","iopub.execute_input":"2024-10-29T10:28:28.768596Z","iopub.status.idle":"2024-10-29T10:28:28.890607Z","shell.execute_reply.started":"2024-10-29T10:28:28.768554Z","shell.execute_reply":"2024-10-29T10:28:28.889452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The probability of receiving at least one helpful vote of 0.2612\nThe probability of receiving at least one helpful vote of 0.2612 for reviews from users who do not recommend the app indicates that around 26% of these reviews are deemed useful by others. This suggests that even negative feedback can be valuable, as users often share specific insights about the app’s shortcomings. The engagement reflected by these helpful votes highlights an active user community, which can provide developers with critical information for future improvements. Overall, this probability emphasizes the importance of user feedback, even when it is not favorable.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Assumiamo che df_sample sia il DataFrame contenente i dati delle recensioni\n\n# Filtriamo le recensioni in base alla raccomandazione\nnon_recommended_reviews = df_sample[df_sample['recommended'] == False]\n\n# Calcoliamo il totale delle recensioni non raccomandate\ntotal_non_recommended = non_recommended_reviews.shape[0]\n\n# Calcoliamo il totale delle recensioni non raccomandate che hanno almeno un voto utile\nreviews_with_helpful_votes = non_recommended_reviews[non_recommended_reviews['votes_helpful'] >= 1].shape[0]\n\n# Calcoliamo la probabilità\nif total_non_recommended > 0:\n    probability = reviews_with_helpful_votes / total_non_recommended\n    print(f\"La probabilità di ricevere almeno un voto utile per le recensioni non raccomandate è: {probability:.4f}\")\nelse:\n    print(\"Non ci sono recensioni non raccomandate nel dataset.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T10:49:03.695624Z","iopub.execute_input":"2024-10-29T10:49:03.696547Z","iopub.status.idle":"2024-10-29T10:49:03.722058Z","shell.execute_reply.started":"2024-10-29T10:49:03.696503Z","shell.execute_reply":"2024-10-29T10:49:03.720979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The probability of receiving at least one helpful vote of 0.5532 \nThe probability of receiving at least one helpful vote of 0.5532 for reviews from users who do not recommend the app suggests that over half of these reviews (approximately 55%) are considered useful by other users. This high probability indicates that even reviews that advise against the app often contain valuable information. The substantial engagement from the community in recognizing helpful insights demonstrates the importance of user feedback, regardless of the sentiment. Such feedback can guide developers in addressing issues and improving their applications.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Assumiamo che df_sample sia il DataFrame contenente i dati delle recensioni\n# Calcoliamo la probabilità di ricevere almeno un voto utile (P(A))\nP_A = (df_sample['votes_helpful'] >= 1).mean()\n\n# Calcoliamo la probabilità che il revisore abbia inviato almeno cinque recensioni prima (P(B))\n# Dobbiamo contare le recensioni per ogni autore e vedere se hanno almeno 5 recensioni\nreviewer_counts = df_sample['author.steamid'].value_counts()\nP_B = (reviewer_counts >= 5).mean()\n\n# Calcoliamo la probabilità che entrambe le condizioni siano vere (P(A ∩ B))\n# Questo implica filtrare il DataFrame per i revisori che hanno almeno 5 recensioni\nreviewers_with_min_five = df_sample[df_sample['author.steamid'].isin(reviewer_counts[reviewer_counts >= 5].index)]\nP_A_and_B = (reviewers_with_min_five['votes_helpful'] >= 1).mean()\n\n# Controlliamo se P(A ∩ B) = P(A) * P(B)\nindependence_check = P_A_and_B == (P_A * P_B)\n\nprint(f\"P(A): {P_A}\")\nprint(f\"P(B): {P_B}\")\nprint(f\"P(A ∩ B): {P_A_and_B}\")\nprint(f\"I due eventi A e B sono indipendenti? {'Sì' if independence_check else 'No'}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T10:57:38.223161Z","iopub.execute_input":"2024-10-29T10:57:38.224150Z","iopub.status.idle":"2024-10-29T10:57:38.379158Z","shell.execute_reply.started":"2024-10-29T10:57:38.224096Z","shell.execute_reply":"2024-10-29T10:57:38.377994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Two events are not independent\nThe results indicate that the two events are not independent, suggesting a relationship between the number of reviews written by a reviewer and the likelihood of receiving at least one helpful vote.\n\nIn essence, if a reviewer has experience (having submitted at least five reviews), their new reviews are more likely to be considered helpful. This could be due to:\n\nCredibility: Experienced reviewers may be seen as more credible.\nQuality: They might write higher-quality reviews.\nUnderstanding: More experienced users may better evaluate games.\nOverall, this suggests that a reviewer's experience positively influences the perceived usefulness of their reviews.","metadata":{}},{"cell_type":"code","source":"import statsmodels.api as sm\n\n# Aggiungiamo una costante per il termine di intercetta\nX = sm.add_constant(data['author.num_games_owned'])  # variabile indipendente\ny = data['review_count']  # variabile dipendente\n\n# Creiamo il modello di regressione\nmodel = sm.OLS(y, X).fit()\nprint(model.summary())\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T11:11:55.404459Z","iopub.execute_input":"2024-10-29T11:11:55.405617Z","iopub.status.idle":"2024-10-29T11:11:55.572501Z","shell.execute_reply.started":"2024-10-29T11:11:55.405563Z","shell.execute_reply":"2024-10-29T11:11:55.571310Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# linear regression\nAfter conducting a statistical analysis using OLS regression, we can state that the hypothesis “reviewers who own a larger number of games are likely to leave fewer reviews on the platform” is not supported by the data.\n\nThe results show that the coefficient for the number of games owned is very low (5.609e-05) and the R-squared is only 0.004, indicating that only 0.4% of the variability in the number of reviews can be explained by the number of games owned. While there is a statistically significant correlation, the effect is negligible and does not justify the idea that owning a greater number of games leads to leaving fewer reviews. In fact, the analysis suggests that the number of games owned does not substantially influence the review-writing behavior.","metadata":{}},{"cell_type":"markdown","source":"# Richiesta al LLM\nHere’s a detailed breakdown of the purposes of histograms, bar plots, scatterplots, and pie charts, along with their insights and how to improve the confidence in the results:\n\n1. Histograms\nPurpose: Histograms are used to represent the distribution of a dataset. They show the frequency of data points within specified intervals (bins).\nInsights:\nThey help identify the shape of the data distribution (e.g., normal, skewed, bimodal).\nThey can reveal outliers, central tendencies, and the spread of the data.\nTrustworthiness: Histograms can be sensitive to bin width. Choosing appropriate bin sizes is crucial; too few bins can oversimplify the data, while too many can create noise. Always consider visualizing the data with different bin sizes.\n2. Bar Plots\nPurpose: Bar plots display categorical data with rectangular bars representing the values of different categories.\nInsights:\nThey allow for easy comparison of the sizes of different categories.\nThey can show trends over time when the bars are arranged chronologically.\nTrustworthiness: Bar plots are straightforward but can be misleading if not scaled appropriately. Ensuring the y-axis starts at zero is essential to avoid exaggerating differences.\n3. Scatterplots\nPurpose: Scatterplots depict the relationship between two quantitative variables by showing data points on a Cartesian plane.\nInsights:\nThey can illustrate correlations (positive, negative, or none) between variables.\nThey help identify clusters, trends, and potential outliers.\nTrustworthiness: The interpretation of scatterplots can be affected by the presence of outliers or the scale of the axes. Conducting correlation analysis in addition to visual inspection can strengthen insights.\n4. Pie Charts\nPurpose: Pie charts show the proportion of parts to a whole, representing categorical data in a circular graph.\nInsights:\nThey provide a visual representation of relative sizes of categories in relation to the total.\nBest used when you have a small number of categories.\nTrustworthiness: Pie charts can be misleading, especially with many categories or similar sizes. They are often less effective than bar plots for comparative purposes.\nImproving Confidence in Insights\nTo enhance the trustworthiness of results derived from these visualizations:\n\nCross-Validation: Use multiple methods to analyze the data. For example, after observing a trend in a histogram, confirm it with statistical tests.\nDocumentation: Refer to literature or authoritative sources for best practices in data visualization.\nSensitivity Analysis: Test how results change with different parameters (e.g., varying bin sizes for histograms or adjusting category definitions for bar plots).\nSupplemental Analysis: Pair visual insights with statistical analyses (e.g., t-tests, ANOVA for bar plots) to support findings with numerical evidence.\nConclusion\nHistograms, bar plots, scatterplots, and pie charts are valuable tools in statistical analysis, each offering unique insights. However, it is essential to approach their results with a critical mindset and consider validating findings with additional statistical methods to ensure robustness and accuracy.","metadata":{}}]}